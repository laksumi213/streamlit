import json
import os
import re
import time

import google.generativeai as genai

# --- Google Sheets Libraries ---
import gspread
import pandas as pd
import streamlit as st
from dotenv import load_dotenv
from duckduckgo_search import DDGS
from google.api_core import exceptions
from gspread_dataframe import set_with_dataframe
from oauth2client.service_account import ServiceAccountCredentials

# --- Selenium Setup ---
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager

# ============================================================
# â˜…è¨­å®šã‚¨ãƒªã‚¢
# ============================================================

if "GOOGLE_API_KEYS" in st.secrets:
    env_keys = st.secrets["GOOGLE_API_KEYS"]
else:
    load_dotenv()
    env_keys = os.getenv("GOOGLE_API_KEYS")

if env_keys:
    API_KEYS = env_keys.split(",")
else:
    API_KEYS = []

import os

import streamlit as st
from dotenv import load_dotenv

# --- Google Sheets Libraries ---

# --- Selenium Setup ---

# ============================================================
# â˜…è¨­å®šã‚¨ãƒªã‚¢
# ============================================================

if "GOOGLE_API_KEYS" in st.secrets:
    env_keys = st.secrets["GOOGLE_API_KEYS"]
else:
    load_dotenv()
    env_keys = os.getenv("GOOGLE_API_KEYS")

if env_keys:
    API_KEYS = env_keys.split(",")
else:
    API_KEYS = []

MODEL_CANDIDATES = ["models/gemini-2.0-flash-exp", "models/gemini-1.5-flash"]
current_key_index = 0


def configure_genai():
    global current_key_index
    if API_KEYS and current_key_index < len(API_KEYS):
        genai.configure(api_key=API_KEYS[current_key_index])


configure_genai()


def generate_ultimate_rotation(prompt):
    global current_key_index
    if not API_KEYS:
        return "ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ãªã—"
    while current_key_index < len(API_KEYS):
        for model_name in MODEL_CANDIDATES:
            try:
                model = genai.GenerativeModel(model_name)
                response = model.generate_content(prompt)
                return response.text
            except exceptions.ResourceExhausted:
                continue
            except Exception as e:
                print(f"Error: {e}")
                continue
        current_key_index += 1
        configure_genai()
    return "ã‚¨ãƒ©ãƒ¼: å…¨ã‚­ãƒ¼æž¯æ¸‡"


# ============================================================
# â˜… Google Sheets æŽ¥ç¶šè¨­å®š
# ============================================================

SHEET_URL = "https://docs.google.com/spreadsheets/d/xxxxxxxx/edit"
if "SHEET_URL" in st.secrets:
    SHEET_URL = st.secrets["SHEET_URL"]


def get_google_sheet_data():
    scope = [
        "https://spreadsheets.google.com/feeds",
        "https://www.googleapis.com/auth/drive",
    ]

    if "gcp_service_account" in st.secrets:
        creds_dict = st.secrets["gcp_service_account"]
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    else:
        json_file = "service_account.json"
        if os.path.exists(json_file):
            creds = ServiceAccountCredentials.from_json_keyfile_name(json_file, scope)
        else:
            st.error("èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None, None

    client = gspread.authorize(creds)
    try:
        sheet = client.open_by_url(SHEET_URL)
        worksheet = sheet.get_worksheet(0)
        data = worksheet.get_all_values()

        if not data:
            return pd.DataFrame(), worksheet

        headers = data.pop(0)
        df = pd.DataFrame(data, columns=headers)
        return df, worksheet
    except Exception as e:
        st.error(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæŽ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return None, None


def save_to_google_sheet(worksheet, df):
    worksheet.clear()
    set_with_dataframe(worksheet, df)


# ============================================================
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æœ¬ä½“
# ============================================================

st.set_page_config(page_title="éŠ€è¡Œãƒžã‚¹ã‚¿ç®¡ç† Cloud", layout="wide")
st.title("ðŸ¦ éŠ€è¡Œæ‰‹ç¶šãå®Œå…¨è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ  (Cloudç‰ˆ)")

# --- â˜…ã“ã“ã‚’å¼·åŒ–ï¼šURLãƒžã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å®šç¾© ---
# è‡ªå‹•æ¤œç´¢ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã‚‚å¤§ä¸ˆå¤«ãªã‚ˆã†ã«ã€ä¸»è¦URLã‚’æœ€åˆã‹ã‚‰æŒã£ã¦ãŠãã¾ã™
BANK_MASTER_DB = {
    "ä¸‰è±UFJéŠ€è¡Œ": "https://www.bk.mufg.jp/tsukau/tetsuduki/souzoku/index.html",
    "ä¸‰äº•ä½å‹éŠ€è¡Œ": "https://www.smbc.co.jp/kojin/souzoku/",
    "ã¿ãšã»éŠ€è¡Œ": "https://www.mizuhobank.co.jp/retail/products/souzoku/index.html",
    "ã‚†ã†ã¡ã‚‡éŠ€è¡Œ": "https://www.jp-bank.japanpost.jp/kojin/tetuzuki/souzoku/kj_tzk_szk_index.html",
    "ã‚ŠããªéŠ€è¡Œ": "https://www.resonabank.co.jp/kojin/souzoku/",
    "åŸ¼çŽ‰ã‚ŠããªéŠ€è¡Œ": "https://www.saitamaresona.co.jp/kojin/souzoku/",
    "æ¨ªæµœéŠ€è¡Œ": "https://www.boy.co.jp/kojin/tetuzuki/souzoku/",
    "åƒè‘‰éŠ€è¡Œ": "https://www.chibabank.co.jp/kojin/procedure/inheritance/",
    "ç¦å²¡éŠ€è¡Œ": "https://www.fukuokabank.co.jp/personal/service/souzoku/",
    "é™å²¡éŠ€è¡Œ": "https://www.shizuokabank.co.jp/personal/procedure/inheritance",
    "å¸¸é™½éŠ€è¡Œ": "https://www.joyobank.co.jp/personal/service/souzoku/",
    "æ¥½å¤©éŠ€è¡Œ": "https://www.rakuten-bank.co.jp/support/inheritance/",
    "ä½ä¿¡SBIãƒãƒƒãƒˆéŠ€è¡Œ": "https://www.netbk.co.jp/contents/support/form/inheritance/",
    "ã‚½ãƒ‹ãƒ¼éŠ€è¡Œ": "https://moneykit.net/visitor/support/inheritance.html",
    "auã˜ã¶ã‚“éŠ€è¡Œ": "https://www.jibunbank.co.jp/procedure/inheritance/",
    "ä¸‰äº•ä½å‹ä¿¡è¨—éŠ€è¡Œ": "https://www.smtb.jp/personal/procedure/inheritance",
    "ä¸‰è±UFJä¿¡è¨—éŠ€è¡Œ": "https://www.tr.mufg.jp/shisan/souzoku_tetsuzuki.html",
    "ã¿ãšã»ä¿¡è¨—éŠ€è¡Œ": "https://www.mizuho-tb.co.jp/souzoku/tetsuzuki/",
}


def find_bank_url(bank_name):
    """
    1. ã¾ãšãƒžã‚¹ã‚¿DBã‚’è¦‹ã‚‹
    2. ãªã‘ã‚Œã°æ¤œç´¢ã™ã‚‹ï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰ã§ã¯å¤±æ•—ã—ã‚„ã™ã„ã®ã§ã‚ãã¾ã§äºˆå‚™ï¼‰
    """
    # ãƒžã‚¹ã‚¿ã«ã‚ã‚Œã°ãã‚Œã‚’è¿”ã™ï¼ˆé«˜é€Ÿãƒ»ç¢ºå®Ÿï¼‰
    if bank_name in BANK_MASTER_DB:
        return BANK_MASTER_DB[bank_name]

    # ãªã‘ã‚Œã°æ¤œç´¢ï¼ˆäºˆå‚™ï¼‰
    try:
        query = f"{bank_name} ç›¸ç¶šæ‰‹ç¶šã"
        results = DDGS().text(query, max_results=1)
        if results:
            return results[0]["href"]
    except:
        return None
    return None


def ask_gemini_to_extract(html_text):
    prompt = f"""
    ä»¥ä¸‹ã®HTMLã‹ã‚‰éŠ€è¡Œæƒ…å ±ã‚’æŠ½å‡ºã—ã€å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    ä½™è¨ˆãªè£…é£¾ã¯ä¸€åˆ‡ä¸è¦ã§ã™ã€‚
    
    {{
        "phone": "é›»è©±ç•ªå·", "hours": "å—ä»˜æ™‚é–“",
        "method": "æ‰‹ç¶šãæ–¹æ³•", "summary": "è¦ç´„"
    }}
    HTML: {html_text[:30000]} 
    """
    return generate_ultimate_rotation(prompt)


def extract_json_from_text(text):
    try:
        match = re.search(r"\{.*\}", text, re.DOTALL)
        if match:
            return json.loads(match.group(0))
    except:
        pass
    return None


def process_single_bank(bank_name, target_url):
    # URLã®è£œå®Œãƒ­ã‚¸ãƒƒã‚¯
    if not target_url or pd.isna(target_url) or target_url == "":
        st.write(f"ðŸ”URLç¢ºèªä¸­: {bank_name}...")
        found = find_bank_url(bank_name)  # ã“ã“ã§ãƒžã‚¹ã‚¿DBãŒåŠ¹ã
        if found:
            target_url = found
            st.write(f"   â†’ URLã‚»ãƒƒãƒˆ: {target_url}")
        else:
            return None, "URLãªã—", ""

    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå½è£…ï¼ˆã‚¢ã‚¯ã‚»ã‚¹æ‹’å¦å¯¾ç­–ï¼‰
    options.add_argument(
        "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )

    try:
        driver = webdriver.Chrome(
            service=ChromeService(ChromeDriverManager().install()), options=options
        )
        driver.set_page_load_timeout(60)  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå»¶é•·
        driver.get(target_url)
        time.sleep(5)  # èª­ã¿è¾¼ã¿å¾…ã¡å»¶é•·

        body = driver.find_element("tag name", "body").text
        driver.quit()

        json_text = ask_gemini_to_extract(body)
        return json_text, "Success", target_url
    except Exception as e:
        return None, f"Error: {str(e)}", target_url


# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---

df, worksheet = get_google_sheet_data()

# ç©ºã®å ´åˆã®åˆæœŸåŒ–
if df is not None and df.empty:
    bank_names = list(BANK_MASTER_DB.keys())
    # åˆæœŸURLã‚‚ã‚»ãƒƒãƒˆã™ã‚‹
    init_urls = [BANK_MASTER_DB[name] for name in bank_names]

    df = pd.DataFrame(
        {
            "é‡‘èžæ©Ÿé–¢å": bank_names,
            "Webã‚µã‚¤ãƒˆURL": init_urls,
            "é›»è©±ç•ªå·": [""] * len(bank_names),
            "å—ä»˜æ™‚é–“": [""] * len(bank_names),
            "æ‰‹ç¶šãæ–¹æ³•": [""] * len(bank_names),
            "AIè¦ç´„": ["æœªå–å¾—"] * len(bank_names),
            "æœ€çµ‚æ›´æ–°": ["-"] * len(bank_names),
        }
    )
    save_to_google_sheet(worksheet, df)
    st.rerun()

st.markdown("### ðŸš€ ä¸€æ‹¬è‡ªå‹•åŽé›†")
col1, col2 = st.columns([2, 1])

with col1:
    if st.button("å…¨éŠ€è¡Œæ›´æ–° (Cloud)", type="primary"):
        if df is not None:
            total = len(df)
            bar = st.progress(0)
            status_text = st.empty()

            for i, row in df.iterrows():
                bank = row["é‡‘èžæ©Ÿé–¢å"]
                # æ—¢å­˜URLãŒã‚ã‚Œã°ä½¿ã†ã€ãªã‘ã‚Œã°ãƒžã‚¹ã‚¿ã‹ã‚‰å¼•ã
                current_url = (
                    row["Webã‚µã‚¤ãƒˆURL"] if "Webã‚µã‚¤ãƒˆURL" in df.columns else ""
                )

                status_text.text(f"ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {bank} ...")

                res_json_text, status, final_url = process_single_bank(
                    bank, current_url
                )

                if final_url:
                    df.at[i, "Webã‚µã‚¤ãƒˆURL"] = final_url

                if status == "Success" and res_json_text:
                    data = extract_json_from_text(res_json_text)
                    if data:
                        df.at[i, "é›»è©±ç•ªå·"] = data.get("phone", "ä¸æ˜Ž")
                        df.at[i, "å—ä»˜æ™‚é–“"] = data.get("hours", "ä¸æ˜Ž")
                        df.at[i, "æ‰‹ç¶šãæ–¹æ³•"] = data.get("method", "ä¸æ˜Ž")
                        df.at[i, "AIè¦ç´„"] = data.get("summary", "æŠ½å‡ºæˆåŠŸ")
                    else:
                        df.at[i, "AIè¦ç´„"] = "JSONè§£æžå¤±æ•—"
                elif status != "Success":
                    df.at[i, "AIè¦ç´„"] = f"ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: {status}"

                import datetime

                df.at[i, "æœ€çµ‚æ›´æ–°"] = datetime.datetime.now().strftime(
                    "%Y-%m-%d %H:%M"
                )

                save_to_google_sheet(worksheet, df)
                bar.progress((i + 1) / total)

            status_text.success("å®Œäº†ï¼ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¾ã™")
            time.sleep(1)
            st.rerun()

with col2:
    if st.button("âš ï¸ éŠ€è¡Œãƒªã‚¹ãƒˆã‚’åˆæœŸåŒ–ãƒ»å†èª­è¾¼"):
        bank_names = list(BANK_MASTER_DB.keys())
        init_urls = [BANK_MASTER_DB[name] for name in bank_names]

        new_df = pd.DataFrame(
            {
                "é‡‘èžæ©Ÿé–¢å": bank_names,
                "Webã‚µã‚¤ãƒˆURL": init_urls,
                "é›»è©±ç•ªå·": [""] * len(bank_names),
                "å—ä»˜æ™‚é–“": [""] * len(bank_names),
                "æ‰‹ç¶šãæ–¹æ³•": [""] * len(bank_names),
                "AIè¦ç´„": ["æœªå–å¾—"] * len(bank_names),
                "æœ€çµ‚æ›´æ–°": ["-"] * len(bank_names),
            }
        )
        save_to_google_sheet(worksheet, new_df)
        st.warning("ãƒªã‚¹ãƒˆã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸï¼ˆURLå…¥ã‚Šï¼‰ã€‚")
        time.sleep(1)
        st.rerun()

st.markdown("---")
if df is not None:
    column_config = {
        "Webã‚µã‚¤ãƒˆURL": st.column_config.LinkColumn("URL", display_text="é–‹ã")
    }
    edited_df = st.data_editor(
        df, column_config=column_config, num_rows="dynamic", use_container_width=True
    )

    if st.button("æ‰‹å‹•å¤‰æ›´ã‚’ä¿å­˜"):
        save_to_google_sheet(worksheet, edited_df)
        st.success("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜ã—ã¾ã—ãŸ")
current_key_index = 0


def configure_genai():
    global current_key_index
    if API_KEYS and current_key_index < len(API_KEYS):
        genai.configure(api_key=API_KEYS[current_key_index])


configure_genai()


def generate_ultimate_rotation(prompt):
    global current_key_index
    if not API_KEYS:
        return "ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ãªã—"
    while current_key_index < len(API_KEYS):
        for model_name in MODEL_CANDIDATES:
            try:
                model = genai.GenerativeModel(model_name)
                response = model.generate_content(prompt)
                return response.text
            except exceptions.ResourceExhausted:
                continue
            except Exception as e:
                print(f"Error: {e}")
                continue
        current_key_index += 1
        configure_genai()
    return "ã‚¨ãƒ©ãƒ¼: å…¨ã‚­ãƒ¼æž¯æ¸‡"


# ============================================================
# â˜… Google Sheets æŽ¥ç¶šè¨­å®š
# ============================================================

SHEET_URL = "https://docs.google.com/spreadsheets/d/xxxxxxxx/edit"
if "SHEET_URL" in st.secrets:
    SHEET_URL = st.secrets["SHEET_URL"]


def get_google_sheet_data():
    scope = [
        "https://spreadsheets.google.com/feeds",
        "https://www.googleapis.com/auth/drive",
    ]

    if "gcp_service_account" in st.secrets:
        creds_dict = st.secrets["gcp_service_account"]
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    else:
        json_file = "service_account.json"
        if os.path.exists(json_file):
            creds = ServiceAccountCredentials.from_json_keyfile_name(json_file, scope)
        else:
            st.error("èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None, None

    client = gspread.authorize(creds)
    try:
        sheet = client.open_by_url(SHEET_URL)
        worksheet = sheet.get_worksheet(0)
        data = worksheet.get_all_values()

        if not data:
            return pd.DataFrame(), worksheet

        headers = data.pop(0)
        df = pd.DataFrame(data, columns=headers)
        return df, worksheet
    except Exception as e:
        st.error(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæŽ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return None, None


def save_to_google_sheet(worksheet, df):
    worksheet.clear()
    set_with_dataframe(worksheet, df)


# ============================================================
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æœ¬ä½“
# ============================================================

st.set_page_config(page_title="éŠ€è¡Œãƒžã‚¹ã‚¿ç®¡ç† Cloud", layout="wide")
st.title("ðŸ¦ éŠ€è¡Œæ‰‹ç¶šãå®Œå…¨è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ  (Cloudç‰ˆ)")

# --- â˜…ã“ã“ã‚’å¼·åŒ–ï¼šURLãƒžã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å®šç¾© ---
# è‡ªå‹•æ¤œç´¢ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã‚‚å¤§ä¸ˆå¤«ãªã‚ˆã†ã«ã€ä¸»è¦URLã‚’æœ€åˆã‹ã‚‰æŒã£ã¦ãŠãã¾ã™
BANK_MASTER_DB = {
    "ä¸‰è±UFJéŠ€è¡Œ": "https://www.bk.mufg.jp/tsukau/tetsuduki/souzoku/index.html",
    "ä¸‰äº•ä½å‹éŠ€è¡Œ": "https://www.smbc.co.jp/kojin/souzoku/",
    "ã¿ãšã»éŠ€è¡Œ": "https://www.mizuhobank.co.jp/retail/products/souzoku/index.html",
    "ã‚†ã†ã¡ã‚‡éŠ€è¡Œ": "https://www.jp-bank.japanpost.jp/kojin/tetuzuki/souzoku/kj_tzk_szk_index.html",
    "ã‚ŠããªéŠ€è¡Œ": "https://www.resonabank.co.jp/kojin/souzoku/",
    "åŸ¼çŽ‰ã‚ŠããªéŠ€è¡Œ": "https://www.saitamaresona.co.jp/kojin/souzoku/",
    "æ¨ªæµœéŠ€è¡Œ": "https://www.boy.co.jp/kojin/tetuzuki/souzoku/",
    "åƒè‘‰éŠ€è¡Œ": "https://www.chibabank.co.jp/kojin/procedure/inheritance/",
    "ç¦å²¡éŠ€è¡Œ": "https://www.fukuokabank.co.jp/personal/service/souzoku/",
    "é™å²¡éŠ€è¡Œ": "https://www.shizuokabank.co.jp/personal/procedure/inheritance",
    "å¸¸é™½éŠ€è¡Œ": "https://www.joyobank.co.jp/personal/service/souzoku/",
    "æ¥½å¤©éŠ€è¡Œ": "https://www.rakuten-bank.co.jp/support/inheritance/",
    "ä½ä¿¡SBIãƒãƒƒãƒˆéŠ€è¡Œ": "https://www.netbk.co.jp/contents/support/form/inheritance/",
    "ã‚½ãƒ‹ãƒ¼éŠ€è¡Œ": "https://moneykit.net/visitor/support/inheritance.html",
    "auã˜ã¶ã‚“éŠ€è¡Œ": "https://www.jibunbank.co.jp/procedure/inheritance/",
    "ä¸‰äº•ä½å‹ä¿¡è¨—éŠ€è¡Œ": "https://www.smtb.jp/personal/procedure/inheritance",
    "ä¸‰è±UFJä¿¡è¨—éŠ€è¡Œ": "https://www.tr.mufg.jp/shisan/souzoku_tetsuzuki.html",
    "ã¿ãšã»ä¿¡è¨—éŠ€è¡Œ": "https://www.mizuho-tb.co.jp/souzoku/tetsuzuki/",
}


def find_bank_url(bank_name):
    """
    1. ã¾ãšãƒžã‚¹ã‚¿DBã‚’è¦‹ã‚‹
    2. ãªã‘ã‚Œã°æ¤œç´¢ã™ã‚‹ï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰ã§ã¯å¤±æ•—ã—ã‚„ã™ã„ã®ã§ã‚ãã¾ã§äºˆå‚™ï¼‰
    """
    # ãƒžã‚¹ã‚¿ã«ã‚ã‚Œã°ãã‚Œã‚’è¿”ã™ï¼ˆé«˜é€Ÿãƒ»ç¢ºå®Ÿï¼‰
    if bank_name in BANK_MASTER_DB:
        return BANK_MASTER_DB[bank_name]

    # ãªã‘ã‚Œã°æ¤œç´¢ï¼ˆäºˆå‚™ï¼‰
    try:
        query = f"{bank_name} ç›¸ç¶šæ‰‹ç¶šã"
        results = DDGS().text(query, max_results=1)
        if results:
            return results[0]["href"]
    except:
        return None
    return None


def ask_gemini_to_extract(html_text):
    prompt = f"""
    ä»¥ä¸‹ã®HTMLã‹ã‚‰éŠ€è¡Œæƒ…å ±ã‚’æŠ½å‡ºã—ã€å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    ä½™è¨ˆãªè£…é£¾ã¯ä¸€åˆ‡ä¸è¦ã§ã™ã€‚
    
    {{
        "phone": "é›»è©±ç•ªå·", "hours": "å—ä»˜æ™‚é–“",
        "method": "æ‰‹ç¶šãæ–¹æ³•", "summary": "è¦ç´„"
    }}
    HTML: {html_text[:30000]} 
    """
    return generate_ultimate_rotation(prompt)


def extract_json_from_text(text):
    try:
        match = re.search(r"\{.*\}", text, re.DOTALL)
        if match:
            return json.loads(match.group(0))
    except:
        pass
    return None


def process_single_bank(bank_name, target_url):
    # URLã®è£œå®Œãƒ­ã‚¸ãƒƒã‚¯
    if not target_url or pd.isna(target_url) or target_url == "":
        st.write(f"ðŸ”URLç¢ºèªä¸­: {bank_name}...")
        found = find_bank_url(bank_name)  # ã“ã“ã§ãƒžã‚¹ã‚¿DBãŒåŠ¹ã
        if found:
            target_url = found
            st.write(f"   â†’ URLã‚»ãƒƒãƒˆ: {target_url}")
        else:
            return None, "URLãªã—", ""

    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå½è£…ï¼ˆã‚¢ã‚¯ã‚»ã‚¹æ‹’å¦å¯¾ç­–ï¼‰
    options.add_argument(
        "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )

    try:
        driver = webdriver.Chrome(
            service=ChromeService(ChromeDriverManager().install()), options=options
        )
        driver.set_page_load_timeout(60)  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå»¶é•·
        driver.get(target_url)
        time.sleep(5)  # èª­ã¿è¾¼ã¿å¾…ã¡å»¶é•·

        body = driver.find_element("tag name", "body").text
        driver.quit()

        json_text = ask_gemini_to_extract(body)
        return json_text, "Success", target_url
    except Exception as e:
        return None, f"Error: {str(e)}", target_url


# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---

df, worksheet = get_google_sheet_data()

# ç©ºã®å ´åˆã®åˆæœŸåŒ–
if df is not None and df.empty:
    bank_names = list(BANK_MASTER_DB.keys())
    # åˆæœŸURLã‚‚ã‚»ãƒƒãƒˆã™ã‚‹
    init_urls = [BANK_MASTER_DB[name] for name in bank_names]

    df = pd.DataFrame(
        {
            "é‡‘èžæ©Ÿé–¢å": bank_names,
            "Webã‚µã‚¤ãƒˆURL": init_urls,
            "é›»è©±ç•ªå·": [""] * len(bank_names),
            "å—ä»˜æ™‚é–“": [""] * len(bank_names),
            "æ‰‹ç¶šãæ–¹æ³•": [""] * len(bank_names),
            "AIè¦ç´„": ["æœªå–å¾—"] * len(bank_names),
            "æœ€çµ‚æ›´æ–°": ["-"] * len(bank_names),
        }
    )
    save_to_google_sheet(worksheet, df)
    st.rerun()

st.markdown("### ðŸš€ ä¸€æ‹¬è‡ªå‹•åŽé›†")
col1, col2 = st.columns([2, 1])

with col1:
    if st.button("å…¨éŠ€è¡Œæ›´æ–° (Cloud)", type="primary"):
        if df is not None:
            total = len(df)
            bar = st.progress(0)
            status_text = st.empty()

            for i, row in df.iterrows():
                bank = row["é‡‘èžæ©Ÿé–¢å"]
                # æ—¢å­˜URLãŒã‚ã‚Œã°ä½¿ã†ã€ãªã‘ã‚Œã°ãƒžã‚¹ã‚¿ã‹ã‚‰å¼•ã
                current_url = (
                    row["Webã‚µã‚¤ãƒˆURL"] if "Webã‚µã‚¤ãƒˆURL" in df.columns else ""
                )

                status_text.text(f"ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {bank} ...")

                res_json_text, status, final_url = process_single_bank(
                    bank, current_url
                )

                if final_url:
                    df.at[i, "Webã‚µã‚¤ãƒˆURL"] = final_url

                if status == "Success" and res_json_text:
                    data = extract_json_from_text(res_json_text)
                    if data:
                        df.at[i, "é›»è©±ç•ªå·"] = data.get("phone", "ä¸æ˜Ž")
                        df.at[i, "å—ä»˜æ™‚é–“"] = data.get("hours", "ä¸æ˜Ž")
                        df.at[i, "æ‰‹ç¶šãæ–¹æ³•"] = data.get("method", "ä¸æ˜Ž")
                        df.at[i, "AIè¦ç´„"] = data.get("summary", "æŠ½å‡ºæˆåŠŸ")
                    else:
                        df.at[i, "AIè¦ç´„"] = "JSONè§£æžå¤±æ•—"
                elif status != "Success":
                    df.at[i, "AIè¦ç´„"] = f"ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: {status}"

                import datetime

                df.at[i, "æœ€çµ‚æ›´æ–°"] = datetime.datetime.now().strftime(
                    "%Y-%m-%d %H:%M"
                )

                save_to_google_sheet(worksheet, df)
                bar.progress((i + 1) / total)

            status_text.success("å®Œäº†ï¼ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¾ã™")
            time.sleep(1)
            st.rerun()

with col2:
    if st.button("âš ï¸ éŠ€è¡Œãƒªã‚¹ãƒˆã‚’åˆæœŸåŒ–ãƒ»å†èª­è¾¼"):
        bank_names = list(BANK_MASTER_DB.keys())
        init_urls = [BANK_MASTER_DB[name] for name in bank_names]

        new_df = pd.DataFrame(
            {
                "é‡‘èžæ©Ÿé–¢å": bank_names,
                "Webã‚µã‚¤ãƒˆURL": init_urls,
                "é›»è©±ç•ªå·": [""] * len(bank_names),
                "å—ä»˜æ™‚é–“": [""] * len(bank_names),
                "æ‰‹ç¶šãæ–¹æ³•": [""] * len(bank_names),
                "AIè¦ç´„": ["æœªå–å¾—"] * len(bank_names),
                "æœ€çµ‚æ›´æ–°": ["-"] * len(bank_names),
            }
        )
        save_to_google_sheet(worksheet, new_df)
        st.warning("ãƒªã‚¹ãƒˆã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸï¼ˆURLå…¥ã‚Šï¼‰ã€‚")
        time.sleep(1)
        st.rerun()

st.markdown("---")
if df is not None:
    column_config = {
        "Webã‚µã‚¤ãƒˆURL": st.column_config.LinkColumn("URL", display_text="é–‹ã")
    }
    edited_df = st.data_editor(
        df, column_config=column_config, num_rows="dynamic", use_container_width=True
    )

    if st.button("æ‰‹å‹•å¤‰æ›´ã‚’ä¿å­˜"):
        save_to_google_sheet(worksheet, edited_df)
        st.success("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜ã—ã¾ã—ãŸ")
